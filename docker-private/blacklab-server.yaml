## Blacklab server config
# For more information consult: https://inl.github.io/BlackLab/configuration-files.html
#
# Config version
configVersion: 2

# Index Locations
indexLocations:
  - /data/index

# User indices
userIndexes: /data/user-index

# Settings related to BlackLab Server's protocol, i.e. requests and responses
protocol:

  # if false, use the new element names in responses: annotatedfield, annotation, etc.
  # if true, use the old element names in responses: complexfield, property, etc.
  # it is recommended to set this to false. the old element names will eventually be removed.
    useOldElementNames: true

# Settings related to tuning server load and client responsiveness
performance:

    # How many search tasks should be able to run simultaneously
    # (set this to take advantage of the cores/threads available to the machine;
    # probably don't set it any larger, as this won't help and might hurt)
    # (-1 to autodetect)
    #maxConcurrentSearches: ${BLACKLAB_THREADPOOL_SIZE}
    maxConcurrentSearches: 40

    # How many threads may a single search task use at most?
    # (lower values will allow more simultaneous searches to run;
    # higher values improve search performance, but will crowd out other searches.
    # e.g. if you set this to the same number as maxConcurrentSearches, a single 
    # search may queue all other searches until it's done)
    maxThreadsPerSearch: 1

    # Abhort a count if the client hasn't asked about it for 30s
    # (lower values are easier on the server, but might abort a count too soon)
    #abandonedCountAbortTimeSec: 30

# Defaults for search parameters
parameters:
  # Default page size is 20
  pageSize:
    default: 20
    max: 5000

  # Write docInfos on grouped hits
  writeHitsAndDocsInGroupedHits: true

  # Decreases the size of the response
  contextSize:
    default: 0
    max: 0



#  Settings for job caching.
cache:

    # The implementation of the Cache
    implementation: ResultsCache
    # Maximum size the cache may grow to (in megabytes), or -1 for no limit.
    # (we can only approximate the cache size, because different tasks refer to the same data.
    # In the real-world we will probably stay well under this. On the other hand, cache size is 
    # a lot smaller than peak memory usage, so don't this too high either; around 15% of total 
    # memory should be an okay value)
    #
    #maxSizeMegs: ${BLACKLAB_CACHE_MAX_MEM}
    maxSizeMegs: 100

    # How many search tasks will we cache at most? (or -1 for no limit)
    # A note about tasks: a request to BlackLab Server routinely results in 3+ simultaneous search tasks
    # being launched: a task to get a window into the sorted hits, which launches a task to get sorted hits,
    # which launches a task to get the unsorted hits. There's also usually a separate task for keeping track
    # of the running total number of hits found (which re-uses the unsorted hits task). The reason for this
    # architecture is that the results of tasks can be more easily re-used in subsequent searches that way:
    # if the sort changes, we can still use the unsorted hits task, etc. Practical upshot of this: number of 
    # tasks does not equal number of searches. Don't set this too low.
    # Also, a better way to limit cache size is using maxSizeMegs, not by specifying an arbitrary number of tasks.
    #maxNumberOfJobs: ${BLACKLAB_MAX_NUMBER_OF_JOBS}
    maxNumberOfJobs: 5000

    # After how much time will a completed search task be removed from the cache? (in seconds)
    # (don't set this too low; instead, set maxSizeMegs, the target size for the cache)
    #maxJobAgeSec: ${BLACKLAB_MAX_JOB_AGE_SEC}
    maxJobAgeSec: 600

    # After how much time should a running search be aborted?
    # (larger values put stress on the server, but allow complicated searches to complete)
    #maxSearchTimeSec: 300

    # How much free memory the cache should shoot for (in megabytes) while cleaning up.
    # Because we don't have direct control over the garbage collector, we can't reliably clean up until
    # this exact number is available. Instead we just get rid of a few cached tasks whenever a
    # new task is added and we're under this target number.
    #targetFreeMemMegs: 100

    # The minimum amount of free memory required to start a new search task. If this memory is not available,
    # an error message is returned.
    #minFreeMemForSearchMegs: 50

# Settings for diagnosing problems
debug:
    #  A list of IPs that will run in debug mode.
    #  In debug mode, ...
    #  - the /cache-info resource show the contents of the job cache
    #    (other debug information resources may be added in the future)
    #  - output is prettyprinted by default (can be overriden with the prettyprint
    #    GET parameter)
    addresses:
    - 127.0.0.1       #  IPv4 localhost
    - 0:0:0:0:0:0:0:1 #  IPv6 localhost

    alwaysAllowDebugInfo: true

    metricsProvider: ConditionalMetricsProvider

    requestInstrumentationProvider: SimpleRequestInstrumentationProvider

# How to determine current user
# (you only need this if you want per-user private indices or authorization)
authentication:
    system:
        class: AuthHttpBasic

# Options for indexing operations, if enabled
indexing:
  #Unlimited number of indices per user
  maxNumberOfIndicesPerUser: -1


# Settings related to logging
log:

    # Where to log detailed information about requests and cache stats
    #sqliteDatabase: /home/user/blacklab/sqlite_log.db

    # What subjects to log messages for
    trace:
        # BL trace settings
        indexOpening: false
        optimization: false
        queryExecution: false

        # BLS trace settings
        cache: false

